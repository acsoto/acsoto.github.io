<ol>
<li><p>为什么作者认为算法透明不足以解决算法的可问责性？</p>
<ol>
<li>取决于静态分析的有效性，识别代码难度高。</li>
<li>通常要对决策的要素和算法，关键的输入输出进行保密。保密可以防止“博弈”，防止用户反过来对预测的过程产生影响，算法透明会导致某些特征失去预测价值，决策价值。某些隐私数据是不应该共享的，同样可能引发法律问题</li>
<li>如果系统的设计未能考虑未来的评估和责任，就不足以验证软件系统属性</li>
<li>对于随机性决策，即使算法透明了，也无法保证每一次的输出结果相同，可预测，例如抽签。</li>
<li>系统设计者要随着时间的推移改变复杂的决策流程，算法，机器学习系统会改变对模型的预测，因此就算知道了源码和数据，也无法预测行为。</li>
</ol>
</li>
<li><p>作者提出的程序规制性是如何实现的？如何评估程序规制性是否解决了算法的可问责性？</p>
</li>
</ol>
<p>实现：软件验证-加密承诺-零知识证明-公平随机选择</p>
<p>通过输入输出的验证，要求系统创建加密承诺，作为数字证据，让开发者在实施前发布承诺，阐述系统将做什么，在实际发布后承诺，阐述系统实际做了什么，用零知识证明确保系统行为对应其承诺等来确保系统虽然是不透明的，但是可通过一系列方法来对算法进行问责。</p>
<ol start="3">
<li>你认为作者提出的程序规制性能否解决算法的可问责性？你是否有解决算法可问责性的新思路新方法？</li>
</ol>
<p>我认为可以解决大部分算法的可问责性，算法只有开发者本人最清楚最熟悉，作者提出的程序规制性要求开发者直接描述自己算法的行为并且做出保证，这样既不限制开发者编写的独立性，也可以保证在发生特殊情况后可以有方法进行问责。算法本质上就是一个解决问题的手段，进行输入，得到输出，是最基本的流程，而让实现问责也基于这个层面可以很好的和算法设计契合。</p>
<p>我认为可以成立专门的不受利益影响的监管组织，类似纪检委，要求其有一定的技术能力，来对大厂开发的算法产生的数据（无论是简单的输入输出，还是机器学习产生的文件）进行保密性的监视，并且定期生成统计文件，此结果不对外界公开，来保证算法不出现违背规章和法律的情况，并且保证如果出现了问题，可以有充足的证据来进行问责。</p>
